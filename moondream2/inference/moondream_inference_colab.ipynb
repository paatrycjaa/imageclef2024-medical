{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# magic/dataset.py\n",
        "\n",
        "import json\n",
        "import logging\n",
        "import os\n",
        "\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class MAGICDataset(Dataset):\n",
        "    \"\"\"_summary_\n",
        "\n",
        "    :param _type_ Dataset: MAGICDataset for ImageCLEF 2024 challenge\n",
        "    \"\"\"\n",
        "    def __init__(self, file_path:str=\"data/\", split:str=\"train\"):\n",
        "        \"\"\"\n",
        "        :param split: which dataset should be chosen\n",
        "        :param file_path: main path with data\n",
        "        \"\"\"\n",
        "        self.json_file = file_path + split + \"_downloaded.json\"\n",
        "        self.folder_path = file_path + \"images/\" + split\n",
        "        self.data = self._get_preprocessed_data()\n",
        "\n",
        "    def _get_preprocessed_data(self):\n",
        "        with open(self.json_file, encoding=\"utf8\") as f :\n",
        "            json_data = json.load(f)\n",
        "        temp_data = []\n",
        "        for sample in json_data:\n",
        "            if len(sample[\"image_ids\"]) != 1 :\n",
        "                logging.warning(f'Different number of images ({len(sample[\"image_ids\"])}) for question than 1')\n",
        "            image_path = self.folder_path + '/' + sample[\"image_ids\"][0] + '.jpg'\n",
        "            if not os.path.exists(image_path):\n",
        "                image_path = self.folder_path + '/' + sample[\"image_ids\"][0] + '.png'\n",
        "                if not os.path.exists(image_path):\n",
        "                    logging.warning(f\"Couldn't find path {image_path}\")\n",
        "                    continue\n",
        "            temp_data.append({\n",
        "                \"image\" : image_path,\n",
        "                \"description\" : sample[\"query_title_en\"],\n",
        "                \"answer\" : sample[\"responses\"][0][\"content_en\"],\n",
        "                \"encounter_id\" : sample[\"encounter_id\"]\n",
        "            })\n",
        "        return temp_data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.data[idx]\n",
        "        prompt = (\n",
        "            \"This is additional information about the dermatology issue on the image: \"\n",
        "            + sample[\"description\"]\n",
        "            + \" What dermatological disease is on the image and how can it be treated?\"\n",
        "        )\n",
        "        return {\n",
        "            \"image\": Image.open(sample[\"image\"]),  # Should be a PIL image\n",
        "            \"qa\": [\n",
        "                {\n",
        "                    \"question\": prompt,\n",
        "                    \"answer\": sample[\"answer\"],\n",
        "                }\n",
        "            ], ## Why array?\n",
        "            \"encounter_id\": sample['encounter_id']\n",
        "        }"
      ],
      "metadata": {
        "id": "_i4ZhfnOdDgG"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install einops"
      ],
      "metadata": {
        "id": "BLCMpp80jcFH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# moondream2/inference.py"
      ],
      "metadata": {
        "id": "XQOKTS88sWd6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_sample_info(encounter_id, question, answer):\n",
        "    print(\"-------------\")\n",
        "    print(f\"{encounter_id=}\")\n",
        "    print(f\"{question=}\")\n",
        "    print(f\"{answer=}\")\n",
        "    print(\"-------------\")"
      ],
      "metadata": {
        "id": "Fon_pZBzrgc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hzS9gprIc6zm"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "model_id = \"vikhyatk/moondream2\"\n",
        "revision = \"2024-04-02\"\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id, trust_remote_code=True, revision=revision\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, revision=revision)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"START\")\n",
        "dataset = MAGICDataset(\"/content/drive/MyDrive/reddit/\", \"valid\")\n",
        "\n",
        "response = []\n",
        "for sample in dataset:\n",
        "    encounter_id = sample[\"encounter_id\"]\n",
        "    question = sample['qa'][0]['question']\n",
        "    encoded_image = model.encode_image(sample['image'])\n",
        "    answer = model.answer_question(encoded_image, question, tokenizer)\n",
        "    result = {\n",
        "        \"encounter_id\": encounter_id,\n",
        "        \"responses\": [{\n",
        "            \"content_en\": answer\n",
        "        }]\n",
        "    }\n",
        "    response.append(result)\n",
        "    with open('/content/drive/MyDrive/CLEF/predictions/moondream2/2025-05-02-valid-prediction.json', 'w') as f:\n",
        "        json.dump(response, f)\n",
        "    print_sample_info(encounter_id, question, answer)"
      ],
      "metadata": {
        "id": "Ob16S4Q9ls6q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}